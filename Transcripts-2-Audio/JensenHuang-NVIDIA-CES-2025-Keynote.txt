
NVIDIA CEO Jensen Huang Keynote at CES 2025
https://www.youtube.com/watch?v=k82RwXqZHY8

Transcript


0:06
this is how intelligence is made a new kind of
0:14
factory generator of tokens the building blocks of
0:21
AI tokens have opened a new frontier the first step into an extraordinary world
0:27
where endless possibilities are born [Music]
0:34
tokens transform words into knowledge and breathe life into
0:41
images they turn ideas into videos and help us safely navigate any
0:51
environment tokens teach robots to move like the Masters
0:56
[Music] Inspire new ways to celebrate our
1:02
victories a martini pleas call light up thank you
1:09
Adam and give us peace of mind when we need it most hi moroka hi Anna it's good
1:16
to see you again hi Emma we're going to take your blood sample today okay don't
1:21
worry I'm going to be here the whole time they bring meaning to numbers
1:30
to help us better understand the world around [Music]
1:40
us predict the dangers that surround [Music]
1:51
us and find cures for the threats within us
1:56
[Music] tokens can bring our Visions to
2:05
[Music] life and restore what we've
2:12
[Music] [Applause] lost
2:17
Zachary I got my voice back
2:22
buddy they help us move forward one small step at a time
2:29
[Music]
2:35
and one giant leap [Music]
2:53
together and here is where it all begins
3:07
welcome to the stage Nvidia founder and CEO Jensen
3:12
[Music] [Applause] [Music] [Applause]
3:20
Wong welcome to CES are you excited to be in Las
3:27
Vegas do you like my Jack it I thought I'd go the other way from
3:34
Gary Shapiro I'm in Las Vegas after all if
3:40
does if this doesn't work out if all of you object well just get used to it I think
3:47
I really think you have to let this sink in in another hour or so you're going to
3:53
feel good about it well uh welcome to
4:01
Nvidia in fact you're inside nvidia's digital twin and we're going to take you to
4:08
Nvidia ladies and gentlemen welcome to
4:13
Nvidia your inside our digital
4:20
twin everything here is generated by
4:26
AI it has been an extraordinary Journey extraordinary year here and uh it
4:32
started in 1993 ready go with
4:38
mv1 we wanted to build computers that can do things that normal computers
4:44
couldn't and mv1 made it possible to have a game console in your
4:49
PC our programming architecture was called UD missing the letter c until a little
4:56
while later but UDA UniFi Unified device architecture and the first developer for
5:04
UDA and the first application that ever worked on UDA was sega's Virtual
5:10
Fighter six years later we invented in 1999 the programmable
5:18
GPU and it started 20 years 20 plus years of
5:24
incredible advance in this incredible processor called the GPU it made modern
5:31
computer Graphics possible and now 30 years later sega's
5:37
Virtual Fighter is completely cinematic this is the new Virtual
5:44
Fighter project that's coming I just can't wait absolutely incredible six years after that six year
5:52
six years after 1999 we invented Cuda so that we could
5:58
explain or or expressed the programmability of our gpus to a rich
6:04
set of algorithms that could benefit from it Cuda initially was difficult to explain and
6:11
it took years in fact it took approximately six years somehow six
6:17
years later six years later or so
6:25
2012 Alex kvki ilas sus and Jeff Hinton
6:30
discovered Cuda used it to process alexnet and the rest of it is history AI
6:38
has been advancing at an incredible Pace since started with perception AI we now
6:45
can understand images and words and sounds to generative AI we can generate
6:51
images and text and sounds and now agentic ai AIS that can
6:58
perceive reason plan and act and then the next phase some of which we'll talk
7:04
about tonight physical AI 2012 now
7:10
magically 2018 something happened that was pretty
7:15
incredible Google's Transformer was released as Bert and the world of AI
7:24
really took off Transformers as you know completely changed the land landcape for
7:30
artificial intelligence in fact it completely changed the landscape for computing
7:35
altogether we recognized properly that AI was not just a new application with a
7:42
new business opportunity but AI more importantly machine learning enabled by
7:49
Transformers was going to fundamentally change how Computing works and
7:56
today Computing is revolutionized in every single layer from hand coding
8:04
instructions that run on CPUs to create software tools that humans use we now
8:09
have machine learning that creates and optimizes new networks that processes on
8:16
gpus and creates artificial intelligence every single layer of the
8:21
technology stack has been completely changed an incredible transformation in
8:28
just 12 years well we can Now understand information
8:33
of just about any modality surely you've seen text and images and sounds and
8:39
things like that but not only can we understand those we can understand amino acids we can understand physics we
8:47
understand them we can translate them and generate them the applications are
8:52
just completely endless in fact almost any AI application that you you see out
8:57
there what modality is the input that it learned from what modality of
9:02
information did it translate to and what modality of information is it generating if you ask these three fundamental
9:09
questions just about every single application could be inferred and so
9:14
when you see application after applications that are Aid driven AI
9:19
native at the core of it this fundamental concept is there machine learning has changed how every
9:26
application is going to be built how computing will be done and the possibilities Beyond
9:33
well gpus gForce in a lot of
9:39
ways all of this with AI is the house that GeForce built GeForce enabled AI to
9:47
reach the masses and now ai is coming home to GeForce there are so many things that
9:54
you can't do without AI let me show you some of it
9:59
now
10:08
[Music]
11:06
[Applause] [Music]
11:14
[Applause] [Music]
11:34
that was realtime computer
11:44
Graphics no computer Graphics researcher no computer scientist would have told
11:50
you that it is possible for us to rate trce every single Pixel at this point we
11:56
Ray tracing is a simulation of light the amount of geometry that you saw was absolutely insane it would have been
12:03
impossible without artificial intelligence there are two fundamental things that we did we used of course
12:10
programmable shading and Ray traced acceleration to produce incredibly beautiful pixels but then we have
12:18
artificial intelligence be conditioned be controlled by that pixel
12:24
to generate a whole bunch of other pixels not only is it able to generate pixels spatially because it's aware of
12:32
what the colors should be it has been trained on a supercomputer back in Nvidia and so the neuron Network that's
12:39
running on the GPU can infer and predict the pixels that we did not render not
12:46
only can can we do that it's called dlss the latest generation of dlss also
12:53
generates Beyond frames it can predict the future generating three additional
12:58
frames for every frame that we calculate what you saw if we just said four frames
13:04
of what you saw because we're going to render one frame and generate three if I said four frames at full HD 4K that's 33
13:13
million pixels or so out of that 33 million pixels we computed only
13:23
two it is an absolute miracle that we can computationally comput tionally
13:29
using programmable shaders and our R traced engine R tracing engine to compute 2 million pixels and have ai
13:36
predict all of the other 33 and as a result we're able to render at
13:43
incredibly high performance because AI does a lot less computation it takes of
13:49
course an enormous amount of training to produce that but once you train it the generation is extremely efficient so
13:57
this is one of the incredible cap abilities of artificial intelligence and that's why there's so many amazing
14:03
things that are happening we used gForce to enable artificial intelligence and
14:08
now artificial intelligence is revolutionizing GeForce everyone today we're announcing
14:15
our next Generation the RTX Blackwell family
14:20
let's take a look
14:29
[Music]
14:45
is
15:05
[Music]
15:12
[Music]
15:19
here it is our brand new gForce
15:24
RTX 50 Series Blackwell architect
15:30
the GPU is just a beast 92 billion transistors
15:36
4,000 tops four pedop flops of AI three
15:41
times higher than the last generation Ada and we need all of it to generate those pixels that I showed you 380 Ray
15:50
tracing Tera flops so that we could for the pixels that we have to compute compute the most beautiful image you
15:56
possibly can and of course 125 Shader teraflops there is actually a concurrent
16:03
Shader teraflops as well as an Inger unit of equal performance so two dual
16:09
shaders one is for floating point one is for integer G7 memory from Micron 1.8
16:16
terabytes Per Second Twice the performance of our last generation and we now have the ability to intermix AI
16:24
workloads with computer graphics workloads and one of the amazing things about this gener eration is the
16:30
programmable Shader is also able to now process neuron networks so the Shader is
16:37
able to carry these neuron networks and as a result we invented neurot texture
16:42
compression and neurom material shading as a result of that you get these
16:47
amazingly beautiful images that are only possible because we use AIS to learn the
16:53
texture learn a compression algorithm and as a result get extraordinary results okay so this is this is uh the
17:01
brand new RTX Blackwell
17:10
9 now even even the even the mechanical
17:15
design is a miracle look at this it's got two fans this whole graphics card is just
17:21
one giant fan you know so the question is where's the graphics card is it literally this
17:27
big the voltage regul to design is state-of-the-art incredible design the
17:33
engineering team did a great job so here it is thank
17:42
you okay so those are the speeds and fees so how does it compare
17:48
well this is RTX 490 I know I know many of you have
17:57
one I I know it look it's $1,599 it is one of the best investments
18:04
you could possibly make you for $15.99 you bring it home to your
18:12
$10,000 PC entertainment Command Center isn't that
18:18
right don't tell me that's not true don't be ashamed it's liquid
18:25
cooled fancy lights all over it you lock it when you
18:33
leave it's it's the modern home theater it makes perfect sense and now for
18:38
$1,500 and99 $15.99 you get to upgrade that and turbocharged the living Daya lights out
18:44
of it well now with the Blackwell family RTX 570 490 performance at 549
18:53
[Applause]
19:01
impossible without artificial intelligence impossible without the Four
19:07
Tops four ter Ops of AI tensor cores impossible without the G7 memories okay
19:14
so 5070 490 performance $549 and here's the whole family starting from 5070 all
19:22
the way up to 5090 5090 twice the performance of a 4090
19:30
starting of course we're producing at very large scale availability starting January well it is incredible but we
19:39
managed to put these in in gigantic performance gpus into a laptop this is a
19:47
570 laptop for $12.99 this 570 laptop has a 4090
19:55
performance I think there's one here somewhere let me show you
20:02
this this is a look at this thing here let me
20:07
here there's only so many pockets ladies and gentlemen Janine
20:14
[Applause] Paul so can you imagine you get this
20:19
incredible graphics card here Blackwell we're going to shrink it and put it in put it in there does that make any
20:26
sense well you can't do that without artificial intelligence and the reason for that is because we're generating
20:32
most of the pixels using pixels using our tensor cores so we retrace only the pixels we need and we generate using
20:40
artificial intelligence all the other pixels we have as a result the amount of the Energy Efficiency is just off the
20:46
charts the future of computer Graphics is neural rendering the fusion of
20:51
artificial intelligence and computer graphics and what's really
20:57
amazing is oh here we go thank you this is a surprisingly kinetic
21:04
keynote and and uh what's really amazing is the family of gpus we're going to put in here and so the 1590 the 1590 will
21:13
fit into a laptop a thin laptop that last laptop was 14 14.9 mm you got a
21:19
5080 5070 TI and 5070 okay so ladies and gentlemen the
21:26
RTX Blackwell family [Applause]
21:37
well GeForce uh brought AI to to the world democratized AI now ai has come
21:45
back and revolutionized GeForce let's talk about artificial intelligence let's
21:51
go to somewhere else at
21:57
Nvidia this this is literally our office this is literally nvidia's
22:03
headquarters okay so let's talk about let's talk about AI the
22:08
industry is chasing and racing to scale
22:13
artificial intelligence int artificial intelligence and the scaling law is a
22:20
powerful model it's an empirical law that has been observed and demonstrated
22:25
by researchers and Industry over several Generations ations and this the the
22:30
scale the scaling law says that the more data you have the training data that you
22:37
have the larger model that you have and the more compute that you apply to it therefore the more effective or the more
22:44
capable your model will become and so the scaling law continues what's really
22:51
amazing is that now we're moving towards of course and the internet is producing about twice twice the amount of data
22:59
every single year as it did last year I think the in the next couple of years we produce uh Humanity will produce more
23:05
data than all of humanity has ever produced uh since the beginning and so
23:10
we're still producing a gigantic amount of data and it's becoming more multimodal video and images and sound
23:18
all of that data could be used to train the fundamental knowledge the foundational knowledge of an AI but
23:26
there are in fact two other scaling laws that has now emerged and it's somewhat
23:32
intuitive the second scaling law is post trining scaling law posttraining scaling
23:39
law uses Technologies techniques like reinforcement learning human feedback
23:44
basically the AI produces and generates answers the hum based on a human query
23:51
the human then of course gives a feedback um it's much more complicated than that but the reinforcement learning
23:56
system uh with a fair number of very high quality prompts causes the AI to
24:03
refine its skills it could find tune its skills for particular domains it could
24:09
be better at solving math problems better at reasoning so on so forth and so it's essentially like having a mentor
24:17
or having a coach give you feedback um after you're done going to school and so
24:22
you you get test you get feedback you improve yourself we also have reinforcement learning AI feedback
24:29
and we have synthetic data generation uh these techniques are rather uh uh Ain to
24:36
if you will uh self-practice uh you know you know the answer to a particular problem and uh you continue to try it
24:44
until you get it right and so an AI could be presented with a very complicated and difficult problem that
24:50
has that is verifiable U functionally and has a has an answer that we
24:55
understand maybe proving a theorem maybe solving a solving a uh geometry problem
25:00
and so these problems uh would cause the AI to produce answers and using reinforcement learning uh it would learn
25:08
how to improve itself that's called post training post training requires an enormous amount of computation but the
25:14
end result produces incredible models we now have a third scaling law and this
25:21
third scaling law has to do with uh what's called test time scaling test
25:26
time scaling is basically when you're being used when you're using the AI uh
25:32
the AI has the ability to now apply a different resource allocation instead of
25:37
improving its parameters now it's focused on deciding how much computation
25:43
to use to produce the answers uh it wants to produce reasoning is a way of thinking
25:50
about this uh long thinking is a way to think about this instead of a direct inference or One-Shot answer you might
25:57
reason about you might break down the problem into multiple steps you might uh generate multiple ideas and uh evaluate
26:05
you know your AI system would evaluate which one of the ideas that you generated was the best one maybe it
26:11
solves the problem step by step so on so forth and so now test time scaling has
26:16
proven to be incredibly effective you're watching this sequence of technology and
26:22
this all of these scaling laws emerge as we see incredible achievements from chat
26:28
GPT to 01 to 03 and now Gemini Pro all of these systems are going through this
26:36
journey step by step by step of pre-training to posttraining to test
26:41
time scaling well the amount of computation that we need of course is incredible and we would like in fact we
26:48
would like in fact that Society has the ability to scale the amount of computation to produce more and more
26:55
novel and better intelligence intelligence of course is the most valuable asset that we have and it can
27:01
be applied to solve a lot of very challenging problems and so scaling law
27:06
it's driving enormous demand for NVIDIA Computing it's driving an enormous demand for this incredible chip we call
27:14
Blackwell let's take a look at Blackwell well Blackwell is in full
27:21
production it is incredible what it looks like so first of all there's some
27:27
uh every every single cloud service provider now have systems up and running uh we have systems here from about 15 uh
27:35
15 15 U uh excuse me 15 computer makers it's being made uh about 200 different
27:42
SKS 200 different configurations they're liquid cooled air cooled x86 Nvidia gray
27:48
CPU versions mvlink 36 by 2 MV links 72
27:53
by1 whole bunch of different types of systems so that we can accommodate just about every single data center in the
27:59
world well this these systems are being currently manufactured in some 45
28:06
factories it tells you how pervasive artificial intelligence is and how much the industry is jumping onto artificial
28:13
intelligence in this new Computing model well the reason why we're driving
28:19
it so hard is because we need a lot more computation and it's very clear it's
28:25
very clear that that um
28:37
Janine you know I it's hard to tell you don't ever want
28:43
to reach your hands into a dark place hang a second is this a good
28:50
idea all right
28:56
[Applause] [Music]
29:08
wait for it wait for
29:16
it I thought I was
29:23
worthy apparently yor didn't think I was worthy all right
29:29
this is my show and tell this is a show and tell so uh this mvlink system this
29:36
right here this mvlink system this is gb200 MV link 72 it is 1 and 12
29:44
tons 600,000 Parts approximately equal to 20
29:51
cars 12 12 120 kilow
29:59
it has um a spine behind it that connects all of these GPU
30:04
together two miles of copper cable 5,000
30:11
cables this is being manufactured in 45 factories around the world we build them
30:18
we liquid cool them we test them we disassemble them shiping parts to the
30:24
data centers because it's 1 and A2 tons we reassemble it outside the data centers and install them the
30:30
manufacturing is insane but the goal of all of this is because the scaling laws are driving Computing so hard that this
30:38
level of computation Blackwell over our last generation improves the performance
30:44
per watt by a factor of four performance per watt by a factor of four perform
30:50
performance per dollar by a factor of three that's basically says that in one
30:55
generation we reduce the cost of training these models by a factor of three or if you want to
31:02
increase um the size of your model by a factor of three it's about the same cost but the important thing is this these
31:09
are generating tokens that are being used by all of us when we use Chad GPT
31:14
or when we use Gemini use our phones in the future just about all of these applications are going to be consuming
31:19
these AI tokens and these AI tokens are being generated by these systems and every single data center is
31:26
limited by power and so if the perf per watt of Blackwell is four
31:33
times our last generation then the revenue that could be generated the amount of business that
31:40
can be generated in the data center is increased by a factor of four and so these AI Factory systems really are
31:46
factories today now the goal of all of this is to so that we can create one giant chip the amount of computation we
31:54
need is really quite incredible and this is basically one giant chip if we would have had to build a chip one here we go
32:02
sorry guys you see that that's cool look at that disco lights in
32:11
here right if we had to build this as one chip obviously this would be the size of the wafer but this doesn't
32:17
include the impact of yield it would have to be probably three or four times the size but what we basically have here
32:23
is 72 Blackwell gpus or 144 dieses this one chip here is 1.4 exop flops the
32:32
world's largest supercomputer fastest supercomputer only recently this entire room supercomputer only recently
32:38
achieved an exf flop plus this is 1.4 exf flops of AI floating Point
32:44
performance it has 14 terabytes of memory but here's the amazing thing the memory bandwidth is 1.2 petabytes per
32:52
second that's basically basically the entire internet traffic that's happening
32:59
right now the entire world's internet traffic is being processed across these chips
33:08
okay and we have um 103 130 trillion transistors in total
33:15
2592 CPU cores whole bunch of networking and so
33:20
these I wish I could do this I don't think I will so these are the black Wells these are our
33:29
connectx networking chips these are the mvy link and we're trying to pretend
33:34
about the Envy the the Envy Ling spine but that's not possible okay and these
33:40
are all of the hbm memories 12 ter 14 terabytes of hbm memory this is what
33:46
we're trying to do and this is the miracle this is the miracle of the Blackwell system the blackwall dies
33:52
right here it is the largest single chip the world's ever made but yet the miracle is really in addition to that
34:01
this is uh the grace black wall system well the goal of all of this of course is so that we can thank you
34:10
thanks boy is there a chair I could sit down for a
34:25
second can I have a m AO
34:39
Ultra how is it possible that we're in the mobe ultra
34:46
Stadium it's like coming to Nvidia and we don't have a GPU for
34:54
you so so we need an enormous the computation because we want to train larger and larger models and these
35:02
inferences these inferences used to be one inference but in the future the AI is going to be talking to itself it's
35:08
going to be thinking it's going to be internally reflecting processing so today when the tokens are being
35:14
generated at you so long as it's coming out at 20 or 30 tokens per second it's
35:20
basically as fast as anybody can read however in the future and right now with uh gp1 you know with the new the pre
35:29
Gemini Pro and the new GP the the 0103 models they're talking to themselves we
35:34
reflecting they thinking and so as you can imagine the rate at which the tokens
35:40
could be ingested is incredibly high and so we need the token rates the token generation rates to go way up and we
35:47
also have to drive the cost way down simultaneously so that the C the quality of service can be extraordinary the cost
35:54
to customers can continue to be low and uh will continue to scale and so that's the fundamental purpose the reason why
36:01
we created MV link well one of the most important things that's happening in the world of Enterprise is a Genentech AI a
36:08
Genentech AI basically is a perfect example of test time scaling it's a AI
36:13
is a system of models some of it is understanding interacting with the customer interacting with the user some
36:20
of it is maybe retrieving information retrieving information from Storage a semantic AI system like a rag uh maybe
36:28
it's going on to to the internet uh maybe it's uh studying a PDF file and so
36:33
it might be using tools it might be using a calculator and it might be using a generative AI to uh generate uh charts
36:39
and such and it's iter it's taking the the problem you gave it breaking it down step by step and it's iterating through
36:45
all these different models well in order to respond to a customer in the future in order for AI to respond it used to be
36:52
ask a question answer start spewing out in the future you ask a question a whole bunch bu of models are going to be
36:58
working in the background and so test time scaling the amount of computation
37:03
used for inferencing is going to go through the roof it's going to go through the roof because we want better
37:09
and better answers well to help the the industry build agentic AI our our go to
37:15
market is not direct to Enterprise customers our go to market is is we work with software developers in the it
37:21
ecosystem to integrate our technology to make possible new capabilities just like
37:27
we did did with Cuda libraries we now want to do that with AI libraries and
37:33
just as the Computing model of the past has apis that are uh doing computer
37:38
Graphics or doing linear algebra or doing fluid dynamics in the future on top of those acceleration libraries C
37:46
acceleration libraries will have ai libraries we've created three things for
37:52
helping the ecosystem build agentic AI Nvidia Nims which are essentially AI
37:58
microservices all packaged up it takes all of this really complicated Cuda software Cuda
38:04
DNN cutless or tensor rtlm or Triton or
38:09
all of these different really complicated software and the model itself we package it up we optimize it
38:15
we put it into a container and you could take it wherever you like and so we have models for vision for understanding
38:21
languages for speech for animation for digital biology and we have some new new
38:28
exciting models coming for physical Ai and these AI models run in every single
38:33
Cloud because nvidia's gpus are now available in every single Cloud it's available in every single OEM so you
38:38
could literally take these models integrate it into your software packages create AI agents that run on Cadence or
38:46
they might be S uh service now agents or they might be sap agents and they could
38:52
deploy it to their customers and run it wherever the customers want to run the software the next layer is what we call
38:57
Nvidia Nemo Nemo is essentially a digital employee
39:06
onboarding and training evaluation system in the future these AI agents are
39:13
essentially digital Workforce that are working alongside your employees um working Al doing things for you on your
39:20
behalf and so the way that you would bring these specialized agents into your
39:26
these special agents into your company is to onboard them just like you onboard an employee and so we have different
39:33
libraries that helps uh these AI agents be uh trained for the type of you know
39:39
language in your company maybe the vocabulary is unique to your company the business process is different the way
39:45
you work is different so you would give them examples of what the work product should look like and they would try to
39:50
generate and you would give a feedback and then you would evaluate them so on so forth and so that uh and you would
39:57
guardrail them you say these are the things that you're not allowed to do these are things you're not allowed to say this and and we even give them
40:03
access to certain information okay so that entire pipeline a digital employee
40:09
pipeline is called Nemo in a lot of ways the IT department of every company is
40:16
going to be the HR department of AI agents in the future today they manage and maintain a
40:23
bunch of software from uh from the IT industry in the future they will Main maintain you know nurture onboard and
40:31
improve a whole bunch of digital agents and provision them to the companies to use okay and so your H your it
40:37
department is going to become kind of like AI agent HR and on top of that we
40:42
provide a whole bunch of blueprints that our ecosystem could could uh take advantage of all of this is completely
40:49
open source and so you could take take it and uh modify the blueprints we have blueprints for all kinds of different
40:55
different types of Agents well today we're also announcing that we're doing something that's really cool and I think
41:00
really clever we're announcing a whole family of models that are based off of
41:06
llama the Nvidia llama neotron language Foundation models llama 3.1 is a
41:14
complete phenomenon the download of llama 3.1 from meta 350 650,000 times something
41:23
like that it has been der red and turned into other
41:29
models uh about 60,000 other different models it it is singularly the reason
41:35
why just about every single Enterprise and every single industry has been activated to start working on AI well
41:40
the thing that we did was we realized that the Llama models really could be better fine-tuned for Enterprise use and
41:48
so we fine-tune them using our expertise and our capabilities and we turn them into the Llama neotron Suite of open
41:56
models there are small ones that interact in uh very very fast response
42:02
time extremely small uh they're uh sup what we call Super llama neotron supers
42:08
they're basically your mainstream versions of your models or your Ultra model the ultra model could be used uh
42:15
to be a teacher model for a whole bunch of other models it could be a reward model evaluator uh a judge for other
42:23
models to create answers and decide whether it's a good answer or not give basically give feedback to other
42:29
models it could be distilled in a lot of different ways basically a teacher model a knowledge distillation uh uh model
42:36
very large very capable and so all of this is now available online well these
42:43
models are incredible it's a a number one in leaderboards for chat leaderboard
42:49
for instruction uh lead leaderboard for retrieval um so the different types of
42:55
functionalities necessary that are used in AI agents around the world uh these are going to be incredible models for
43:02
you we're also working with uh the ecosystem these Tech all of our Nvidia
43:07
AI Technologies are integrated into uh uh the it in Industry uh we have great
43:13
partners and really great work being done at service now at sap at Seaman uh
43:18
for industrial AI uh Cadence is during great work synopsis doing great work I'm
43:23
really proud of the work that we do with perplexity as you know they revolutionize search yeah really
43:28
fantastic stuff uh codium uh every every software engineer in the world this is going to be the next giant AI
43:36
application next giant AI service period is software coding 30 million software
43:43
Engineers around the world everybody is going to have a software assistant uh helping them code uh if if um if not
43:51
obviously you're just you're going to be way less productive and create lesser good code and so this is 30 million
43:58
there's a billion knowledge workers in the world it is very very clear AI
44:03
agents is probably the next robotics industry and likely to be a multi-trillion dollar opportunity well
44:10
let me show you some of the uh blueprints that we've created and some of the work that we've done with our
44:15
partners uh with these AI
44:21
agents AI agents are the new digital Workforce working for and with
44:28
us AI agents are a system of models that reason about a mission break it down
44:34
into tasks and retrieve data or use tools to generate a quality
44:40
response nvidia's agentic AI building blocks Nim pre-trained models and Nemo
44:46
framework let organizations easily develop AI agents and deploy them
44:51
anywhere we will onboard and train our agentic workforces on our company's methods like we do for
44:58
employees AI agents are domain specific task experts let me show you four
45:04
examples for the billions of knowledge workers and students AI research assistant agents ingest complex
45:12
documents like lectures journals Financial results and generate interactive podcasts for easy learning
45:19
by combining a unet regression model with a diffusion model cordi can downscale global weather forecasts down
45:26
from 25 km to 2 km developers like at Nvidia manage
45:32
software security AI agents that continuously scan software for vulnerabilities alerting developers to
45:39
what action is needed Virtual Lab AI agents help
45:45
researchers design and Screen billions of compounds to find promising drug candidates faster than
45:52
ever Nvidia analytics AI agents built on an Nvidia metr blueprint including
45:58
Nvidia Cosmos nimron Vision language models llama neaton llms and Nemo
46:05
retriever Metropolis agents analyze content from the billions of cameras
46:11
generating 100,000 pedes of video per day they enable interactive search
46:17
summarization and automated reporting and help monitor traffic flows
46:23
flagging congestion or danger in industrial facilities they monitor
46:31
processes and generate recommendations or Improvement Metropolis agents centralize
46:38
data from hundreds of cameras and can reroute workers or robots when incidents
46:43
occur the age of agentic AI is here for every
46:52
organization okay
46:57
that was the first pitch at a baseball that was not generated I just felt that
47:03
none of you were impressed okay so ai ai was was created
47:09
in the cloud and for the cloud AI is creating the cloud for the cloud and for
47:15
uh enjoying AI on on phones of course it's perfect um very very soon we're
47:21
going to have a continuous AI that's going to be with you and when you use those metag glasses you could of course
47:27
uh point at something look at something and and ask it you know whatever information you want and so AI is is
47:34
perfect in the CL was creating the cloud is perfect in the cloud however we would love to be able to take that AI
47:40
everywhere I've mentioned already that you could take Nvidia AI to any Cloud but you could also put it inside your
47:45
company but the thing that we want to do more than anything is put it on our PC as well and so as you know Windows 95
47:53
revolutionized the computer industry it made possible this new Suite of multimedia services and it change the
47:59
way that applications was created forever um Windows 95 this this model of
48:05
computing of course is not perfect for AI and so the thing that we would like to do is we would like to have in the
48:13
future your AI basically become your AI assistant and instead of instead of just
48:18
the the 3D apis and the sound apis and the video API you would have generative
48:23
apis generative apis for 3D and generative apis for language and generative AI for sound and so on so
48:29
forth and we need a system that makes that possible while leveraging the
48:35
massive investment that's in the cloud there's no way that we could the world can create yet another way of
48:41
programming AI models it's just not going to happen and so if we could figure out a way to make Windows
48:50
PC a worldclass aipc um it would be completely awesome and it turns out the answer is Windows
48:58
it's Windows wsl2 Windows wsl2 Windows
49:03
wsl2 basically it's two operating systems within one it works perfectly
49:09
it's developed for developers and it's developed uh uh so that you can have access to Bare Metal it's been wsl2 has
49:16
been optimized optimized for cloud native applications it is optimized for and
49:23
very importantly it's been optimized for Cuda and so wsl2 supports Cuda perfectly
49:29
out of the box as a result everything that I showed you with
49:36
Nvidia Nims Nvidia Nemo the blueprints
49:41
that we develop that are going to be up in ai. nvidia.com so long as the
49:47
computer fits it so long as you can fit that model and we're going to have many models that that fit whether it's Vision
49:54
models or language models or speech models or these animation human digital human models all kinds of different
50:01
different types of models are going to be perfect for your PC and it would you download it and it should just run and
50:08
so our focus is to turn Windows wsl2 Windows PC into a Target first class
50:16
platform that we will support and maintain for as long as we shall live and so this is an incredible thing for
50:23
engineers and developers everywhere let let me show you something that we can do with that this is one of the examples of a blueprint we just made for
50:31
you generative AI synthesizes amazing images from Simple Text prompts yet
50:38
image composition can be challenging to control using only words with Nvidia Nim
50:43
microservices creators can use Simple 3D objects to guide AI image generation
50:49
let's see how a concept artist can use this technology to develop the look of a scene they start by laying out 3D assets
50:58
created by hand or generated with AI then use an image generation Nim such as
51:04
flux to create a visual that adheres to the 3D scene add or move objects to refine the
51:13
composition change camera angles to frame the perfect shot or reimagine the whole scene with a
51:20
new prompt assisted by generative AI and
51:26
Nvidia Nim and artists can quickly realize their [Music]
51:33
Vision Nvidia AI for your PCS hundreds of millions of PCS in the
51:40
world with Windows and so we could get them ready for AI uh oems all the PC
51:45
oems we work with just basically all of the world's leading PC oems are going to get their PCS ready for this stack and
51:52
so aips are coming to a home near you
52:02
Linux is
52:08
good okay let's talk about physical AI speaking of Linux let's talk about
52:14
physical AI So Physical AI imagine
52:22
imagine whereas your large language model you give it your your context your
52:30
prompt on the left and it generates tokens one at a time to produce the
52:37
output that's basically how it works the amazing thing is this model in the middle is quite large has billions of
52:45
parameters the context length is incredibly large because you might decide to load in a PDF in my case I
52:51
might load in several PDFs before I ask it a question those PDFs are turned into
52:57
tokens the attention the basic attention characteristic of a transformer has
53:02
every single token find its relationship and relevance against every other token
53:08
so you could have hundreds of thousands of tokens and the computational load
53:14
increases quadratically and it does this that all of the parameters all of the
53:19
input sequence process it through every single layer of the Transformer and it produces one token that's the reason why
53:25
we needed blackw and then the next token is produced when the current token is done it puts the
53:32
current token into the input sequence and takes that whole thing and generates the next token it does it one at a time
53:39
this is the Transformer model it's the reason why it is so so incredibly effective computationally demanding What
53:47
If instead of PDFs it's your surrounding and what if instead of the prompt a
53:53
question it's a request go over there and pick up that that you know that box and bring it back and instead of what is
54:00
produced in tokens its text it produces action tokens well that I just described is a
54:09
very sensible thing for the future of Robotics and the technology is right around the corner but what we need to do
54:16
is we need to create the effective effectively the world model of you know as opposed to GPT
54:24
which is a language model and this World model has to understand the language of the world it has to understand physical
54:31
Dynamics things like gravity and friction and inertia it has to
54:36
understand geometric and spatial relationships it has to understand cause and effect if you drop something a fall
54:42
to the ground if you you know poke at it it tips over it has to understand object
54:48
permanence if you roll a ball over the kitchen counter when it goes off the other side the ball didn't leave into
54:54
another quantum universe that that's still there and so all of these types of
54:59
understanding is intuitive understanding that we know that most models today have a very hard time with and so we would
55:06
like to create a world we need a world Foundation model today we're announcing a very big thing we're announcing Nvidia
55:14
Cosmos a world Foundation model that is designed that was created to understand
55:21
the physical world and the only way for you to really understand this is to see it let's
55:29
[Music] flip the next Frontier of AI is physical
55:36
AI model performance is directly related to data availability but physical world
55:42
data is costly to capture curate and label Nvidia Cosmos is a world
55:49
Foundation model development platform to Advance Physical AI it includes Auto
55:55
regressive world found Foundation models diffusion-based World Foundation models Advanced
56:01
tokenizers and an Nvidia Cuda an AI accelerated data
56:07
pipeline Cosmos models ingest text image or video prompts and generate virtual
56:13
world States as videos Cosmos Generations prioritize the unique requirements of Av and Robotics
56:20
use cases like real world environments lighting and object permanence
56:27
developers use Nvidia Omniverse to build physics-based geospatially accurate scenarios then
56:34
output Omniverse renders into Cosmos which generates photoreal physically based synthetic
56:40
[Music]
56:51
data whether diverse objects or environments
56:58
conditions like weather or time of day or Edge case
57:04
scenarios developers use Cosmos to generate worlds for reinforcement learning AI feedback to improve policy
57:13
models or to test and validate model performance even across multisensor
57:21
views Cosmos can generate tokens in real time bringing the power of foresight and
57:27
Multiverse simulation to AI models generating every possible future to help
57:33
the model select the right path working with the world's developer
57:38
ecosystem Nvidia is helping Advance the next wave of physical
57:45
[Music] AI Nvidia
57:51
Cosmos Nvidia Cosmos Nvidia Cosmos the world's first
57:58
world Foundation model it is trained on 20 million hours of video the 20 million
58:06
hours of video focuses on physical Dynamic things so n n Dynamic nature
58:12
nature themes themes uh humans uh walking uh hands moving uh manipulating
58:19
things uh you know things that are uh fast camera movements it's really about
58:24
teaching the AI not about generating creative content but teaching the AI to
58:30
understand the physical world and from this with this physical AI there are
58:35
many Downstream things that we could uh do as a result we could do synthetic data generation to train uh models we
58:43
could distill it and turn it into effectively the seed the beginnings of a robotics model you could have it
58:49
generate multiple physically based physically plausible uh scenarios that
58:56
the future basically do a doctor strange um you could uh because because this model understands the physical world of
59:02
course you saw a whole bunch of images generated this model understanding the physical world it also uh could do of
59:08
course captioning and so it could take videos caption it incredibly well and
59:14
that captioning and the video could be used to train large language models
59:21
multimodality large language models and uh so you could use this technology to
59:26
use this Foundation model to train robotics robots as well as larger language models and so this is the
59:32
Nvidia Cosmos the platform has an auto regressive model for real-time applications has diffusion model for a
59:39
very high quality image generation it's incredible tokenizer basically learning
59:44
the vocabulary of uh real world and a data pipeline so that if you would like
59:49
to take all of this and then train it on your own data this data pipeline because there's so much data involved we've
59:56
accelerated everything end to endend for you and so this is the world's first data processing pipeline that's Cuda
1:00:02
accelerated as well as AI accelerated all of this is part of the cosmos platform and today we're announcing that
1:00:09
Cosmos is open licensed it's open available on
1:00:19
GitHub we hope we hope that this moment and there's a there's a small medium
1:00:24
large for uh uh very fast models um you know mainstream models and also teacher
1:00:30
models basically not knowledge transfer models Cosmo Cosmos World Foundation
1:00:36
model being open we really hope will do for the world of Robotics and Industrial AI what llama 3 has done for Enterprise
1:00:45
AI the magic happens when you connect Cosmos to Omniverse and the reason
1:00:51
fundamentally is this Omniverse is a physics grounded not physically grounded
1:00:59
but physics grounded it's algorithmic physics principled physics simulation
1:01:05
grounded system it's a simulator when you connect that to
1:01:10
Cosmos it provides the grounding the ground truth that can control and to
1:01:16
condition the Osmos generation as a result what comes out of Osmos is grounded on Truth this is exactly the
1:01:23
same idea as connecting a large language model model to a rag to a retrieval
1:01:28
augmented generation system you want to ground the AI generation on ground truth
1:01:34
and so the combination of the two gives you a physically simulated a physically
1:01:41
grounded Multiverse generator and the application the use cases are really
1:01:47
quite exciting and of course uh for robotics uh for industrial applications
1:01:52
uh it is very very clear this Cosmos plus o Omniverse plus Cosmos represents the
1:02:00
Third computer that's necessary for building robotic systems every robotics
1:02:05
company will ultimately have to build three computers a robotics the robotics system could be a factory the robotics
1:02:11
system could be a car it could be a robot you need three fundamental computers one computer of course to
1:02:17
train the AI we call the dgx computer to train the AI another of course when
1:02:24
you're done to deploy the AI we call that agx that's inside the car in the robot or in an AMR or you know at the uh
1:02:32
in a in a stadium or whatever it is these computers are at the edge and
1:02:37
they're autonomous but to connect the two you need a digital twin and this is all the simulations that you were seeing
1:02:43
the digital twin is where the AI that has been trained goes to practice to be
1:02:50
refined to do its synthetic data generation reinforcement learning AI feedback such and such and so it's the
1:02:57
digital twin of the AI these three computers are going to be working interactively nvidia's strategy for uh
1:03:04
the industrial world and we've been talking about this for some time is this three computer
1:03:09
system you know instead of a three three body problem we have a three Computer Solution and so it's the Nvidia
1:03:22
robotics so let me give you three examples all right so the first example is uh uh
1:03:29
how we apply apply all of this to Industrial digitalization there millions
1:03:36
of factories hundreds of thousands of warehouses that's basically it's the backbone of A50 trillion doll
1:03:43
manufacturing industry all of that has to become software defined all of that
1:03:48
has has to have Automation in the future and all of it will be infused with robotics well we're partnering with Keon
1:03:56
the world's leading Warehouse automation Solutions provider and Accenture the
1:04:03
world's largest professional services provider and they have a big focus in digital manufacturing and we're working
1:04:10
together to create something that's really special and I'll show you that in the second but our go to market is
1:04:16
essentially the same as all of the other software uh platforms and all the technology platforms that we have
1:04:22
through the uh developers and ecosystem Partners uh and we have just just a
1:04:29
growing number of ecosystem Partners connecting to Omniverse and the reason for that is very clear everybody wants
1:04:36
to digitalize the future of Industries there's so much waste so much opportunity for Automation in that $50
1:04:43
trillion doar of the world's GDP so let's take a look at that this one one p one example that we're doing with Keon
1:04:49
and Accenture Keon the supply chain solution
1:04:55
company Accenture a global leader in Professional Services and Nvidia are
1:05:01
bringing physical AI to the $1 trillion warehouse and Distribution Center Market
1:05:08
managing high- Performance Warehouse Logistics involves navigating a complex web of decisions influenced by
1:05:15
constantly shifting variables these include daily and seasonal demand changes space constraints Workforce
1:05:23
availability and the integration of of diverse robotic and automated systems
1:05:28
and predicting operational kpis of a physical Warehouse is nearly impossible
1:05:34
today to tackle these challenges Keon is adopting Mega an Nvidia Omniverse
1:05:40
blueprint for building industrial digital twins to test and optimize robotic fleets first Keon's warehouse
1:05:48
management solution assigns tasks to the industrial AI brains in the digital twin
1:05:54
such as moving a load from from a buffer location to a shuttle storage solution the robot's brains are in a
1:06:01
simulation of a physical Warehouse digitalized into Omniverse using open USD connectors to aggregate CAD video
1:06:09
and image to 3D Light Art to point cloud and AI generated data the fleet of
1:06:16
robots execute tasks by perceiving and reasoning about their Omniverse digital
1:06:22
twin environment planning their next motion and acting the robot brains can see the resulting
1:06:28
State through sensor simulations and decide their next action the loop continues while Mega precisely tracks
1:06:36
the state of everything in the digital twin now Keon can simulate infinite
1:06:42
scenarios at scale while measuring operational kpis such as throughput
1:06:48
efficiency and utilization all before deploying changes to the physical
1:06:53
Warehouse together with Nvidia Keon and Accenture are Reinventing
1:06:58
industrial autonomy in the future is that that's incredible everything is in
1:07:05
simulation in the future in the future every Factory will have a digital twin
1:07:12
and that digital twin operates exactly like the real factory and in fact you
1:07:17
could use Omniverse with Cosmos to generate a whole bunch of future scenarios and you pick then an AI
1:07:24
decides which which one of the scenarios are the most optimal for whatever kpis and that becomes the programming
1:07:30
constraints the program if you will the AI that will be uh deployed into the real factories the next example
1:07:37
autonomous vehicles the AV revolution has arrived after so many years with weo
1:07:43
success and Tesla's success it is very very clear autonomous vehicles has
1:07:48
finally arrived well our offering to this industry is the three computers the
1:07:54
training systems the training the AIS the simulation systemss and and the and the synthetic data generation systems
1:08:00
Omniverse and now Cosmos and also the computer that's inside the car each car
1:08:06
company might might work with us in a different way use one or two or three of the computers we're working with just
1:08:12
about every major car company around the world whmo and zuk and Tesla of course
1:08:17
in their data center byd the largest uh EV company in the world jlr has got a
1:08:22
really cool car coming Mercedes because a fleet of cars coming with Nvidia starting with this starting this year
1:08:27
going to production and I'm super super pleased to announce that today Toyota
1:08:33
and Nvidia are going to partner together to create their next Generation
1:08:43
AVS just so many so many cool companies uh lucid and rivan and Shi and of course
1:08:50
uh Volvo just so many different companies Wabi is uh building uh self-driving trucks Aurora we announced
1:08:57
this week also that Aurora is going to use Nvidia to build self-driving trucks autonomous 100 million cars build each
1:09:05
year a billion cars vehicles on a road all over the world a trillion miles that
1:09:10
are driven around the world each year that's all going to be either highly
1:09:15
autonomous or you know fully autonomous coming up and so this is going to be a very L very large industry I predict
1:09:22
that this will likely be the first multi-trillion dollar robotics industry this IND this business
1:09:28
for us um notice in just just a few of these cars that are starting to ramp
1:09:34
into the world uh our business is already $4 billion and this year probably on a run rate of about $5
1:09:40
billion so really significant business already this is going to be very large well today we're announcing that our
1:09:46
next generation processor for the car our next generation computer for the car is called Thor I have one right here
1:09:53
hang on a second okay this is
1:09:58
Thor this is Thor this is this is a robotics
1:10:05
computer this is a robotics computer takes sensors and just a Madness amount
1:10:11
of sensor information process it you know een teed cameras high resolution
1:10:20
Radars Liars they're all coming into this chip and this chip has to process all that sensor turn them into tokens
1:10:27
put them into a Transformer and predict the next PATH and this AV computer is
1:10:34
now in full production Thor is 20 times the processing capability of our last
1:10:40
generation Orin which is really the standard of autonomous vehicles today and so this is just really quite quite
1:10:47
incredible Thor is in full production this robotics processor by the way also goes into a full robot and so it could
1:10:53
be an AMR it could be a human or robot could be the brain it could be the
1:10:58
manipulator this Rob this processor basically is a universal robotics
1:11:04
computer the second part of our drive system that I'm incredibly proud of is
1:11:10
the dedication to safety Drive OS I'm pleased to announce is now the first
1:11:17
softwar defined programmable AI computer that has been certified up to asold D
1:11:24
which is the highest standard of functional safety for automobiles the
1:11:30
only and the highest and so I'm really really proud of this asold ISO
1:11:36
26262 it is um the work of some 15,000 engineering years this is just
1:11:43
extraordinary work and as a result of that Cuda is now a functional safe
1:11:49
computer and so if you're building a robot Nvidia Cuda y
1:11:58
okay so so now I wanted to I told you I was going to show you what would we use Omniverse and Cosmos to do in the
1:12:06
context of self-driving cars and you know today instead of showing you a whole bunch of uh uh videos of of cars
1:12:14
driving on the road I'll show you some of that too um but I want to show you how we use the car to reconstruct
1:12:22
digital twins automatically using Ai and use that capability to train future am
1:12:29
models okay let's play it the autonomous vehicle Revolution is
1:12:37
here building autonomous vehicles like all robots requires three computers
1:12:44
Nvidia dgx to train AI models Omniverse to test drive and generate synthetic
1:12:50
data and drive agx a supercomputer in the car
1:12:55
building safe autonomous vehicles means addressing Edge scenarios but real world
1:13:01
data is limited so synthetic data is essential for
1:13:06
training the autonomous vehicle data Factory powered by Nvidia Omniverse AI
1:13:12
models and Cosmos generates synthetic driving scenarios that enhance training
1:13:18
data by orders of magnitude first omnimap fuses map and
1:13:24
geospatial data to construct drivable 3D
1:13:31
environments driving scenario variations can be generated from replay Drive logs
1:13:36
or AI traffic generators next a neural reconstruction
1:13:42
engine uses autonomous vehicle sensor logs to create High Fidelity 4D
1:13:48
simulation environments it replays previous drives in 3D and generates scenario Vari ations
1:13:55
to amplify training data finally edify 3DS automatically
1:14:01
searches through existing asset libraries or generates new assets to
1:14:07
create Sim ready scenes the Omniverse scenarios are used
1:14:15
to condition Cosmos to generate massive amounts of photo realistic data reducing
1:14:20
the Sim toore Gap and with text prompts generate near
1:14:26
infinite variations of the driving scenario with Cosmos neotron video
1:14:33
search the massively scaled synthetic data set combined with recorded drives
1:14:39
can be curated to train models nvidia's AI data Factory scales
1:14:47
hundreds of drives into billions of effective miles setting the standard for
1:14:52
safe and advanced autonomous driving [Music]
1:14:59
is that incredible we take take thousands of drives and
1:15:08
turn them into billions of miles we are going to have mountains of training data
1:15:14
for autonomous vehicles of course we still need actual cars on the road of course we will continuously collect data
1:15:21
for as long as we shall live however synthetic data generation using this
1:15:26
Multiverse physically based physically grounded capability so that we generate
1:15:32
data for training AIS that are physically grounded and accurate and or plausible so that we could have an
1:15:38
enormous amount of data to train with the AV industry is here uh this is an incredibly exciting time super super
1:15:45
super uh uh excited about the next several years I think you're going to see just as computer Graphics was
1:15:51
revolutionized such incredible pace you're going to see the pace of Av development increasing tremendously over
1:15:57
the next several
1:16:08
years I I think I think um I I think the next part is is
1:16:17
robotics so um
1:16:26
human robots my
1:16:36
[Applause] friends the chat GPT moment for General
1:16:42
robotics is just around the corner and in fact all of the enabling technologies that I've been talking about is going to
1:16:50
make it possible for us in the next several years to see very rapid break breakthroughs surprising breakthroughs
1:16:56
in in general robotics now the reason why General robotics is so important is whereas robots with tracks and wheels
1:17:03
require special environments to accommodate them there are three
1:17:09
robots three robots in the world that we can make that require no green
1:17:15
fields Brown field adaptation is perfect if we if we could possibly build these
1:17:20
amazing robots we could deploy them in exactly the world that we've built for ourselves these three robots are one
1:17:29
agentic robots agentic AI because you know they're information workers so long
1:17:34
as they could accommodate uh the computers that we have in our offices is going to be great number two
1:17:40
self-driving cars and the reason for that is we spent 100 plus years building roads and cities and then number three
1:17:47
human or robots if we have the technology to solve these three this
1:17:53
will be the largest technology industry IND the world's ever seen and so we
1:17:58
think that robotics era is just around the corner the critical capability is
1:18:04
how to train these robots in the case of human or robots the imitation information is
1:18:12
rather hard to collect and the reason for that is uh in the case of car you just drive it we're driving cars all the
1:18:17
time in the case of these human robots the imitation information the the human
1:18:23
demonstration is rather laborious is to do and so we need to come up with a clever way to take hundreds of
1:18:30
demonstrations thousands of human demonstrations and somehow use artificial intelligence and
1:18:37
Omniverse to synthetically generate millions
1:18:44
of synthetically generated motions and from
1:18:49
those motions the AI can learn uh how to perform a task let me show you how that's
1:19:05
done developers around the world are building the next wave of physical AI embodied robots
1:19:13
humanoids developing general purpose robot models requires massive amounts of
1:19:18
real world data which is costly to capture and curate Nvidia Isaac Groot helps tackle
1:19:25
these challenges providing humanoid robot developers with four things robot Foundation
1:19:31
models data pipelines simulation
1:19:36
Frameworks and a Thor robotics computer the Nvidia Isaac Groot
1:19:43
blueprint for synthetic motion generation is a simulation workflow for imitation learning enabling developers
1:19:50
to generate exponentially large data sets from a small number of
1:19:55
demonstrations first Groot teleop enables skilled human workers to portal
1:20:01
into a digital twin of their robot using the Apple Vision Pro this means operators can capture
1:20:08
data even without a physical robot and they can operate the robot in a risk-free environment eliminating the
1:20:14
chance of physical damage or wear and tear to teach a robot a single task
1:20:21
operators capture motion trajectories through a handful of teleoperated demonstrations then use Groot mimic to
1:20:28
multiply these trajectories into a much larger data set next they use Gro gen built on
1:20:37
Omniverse and Cosmos for domain randomization and 3D to real
1:20:42
upscaling generating an exponentially larger data
1:20:48
set the Omniverse and Cosmos Multiverse simulation engine provides a massively
1:20:53
scaled data set to train the robot policy once the policy is trained
1:21:00
developers can perform software in the loop testing and validation in Isaac Sim
1:21:05
before deploying to the real robot the age of General robotics is
1:21:11
arriving powered by Nvidia Isaac
1:21:18
Groot we're going to have mountains of data to train robots with
1:21:24
Nvidia Isaac group Nvidia Isaac group this is our platform to provide
1:21:30
technology platform technology elements to the robotics industry to accelerate the development of General
1:21:36
Robotics and um well I have one more thing that I want to show you none of
1:21:41
none of this none of this would be possible if not for uh this incredible
1:21:47
project that we started uh about a decade ago inside the company what called project project digits deep
1:21:54
learning GPU intelligence training system
1:22:00
digits well before we launched it uh I shrunk it to
1:22:06
dgx and to harmonize it with RTX agx ovx and all of the other X's
1:22:13
that we have in the company and and um I and and it really revolutionized uh djx1
1:22:21
really revolutionized where where's djx1 dgx-1 revolutionized artificial
1:22:28
intelligence the reason why we built it was because we wanted to uh make it
1:22:33
possible for researchers and startups to have an out-of-the-box AI supercomputer imagine the way supercomputers were
1:22:39
built in the past you really have to uh build your own facility and you have to go build your own infrastructure and
1:22:45
really engineer it into existence and so we created a supercomputer for AI for AI
1:22:51
development for researchers and and startups that comes literally one out of the box I delivered the first one to a
1:22:56
startup company in 2016 called open Ai and Elon was there and and Ilia sus was
1:23:02
there and many of Nvidia Engineers were there and and um uh we we celebrated the arrival of djx1 and obviously uh it
1:23:12
revolutionized uh artificial intelligence and Computing um but now artificial intelligence is everywhere
1:23:18
it's not just in researchers and and and startup Labs you know we want artificial intelligence as I mentioned in the
1:23:23
beginning of our this is now the new way of doing Computing this is the new way of doing software every software engineer every
1:23:30
engineer every creative artist everybody who uses computers today as a tool will
1:23:37
need a AI supercomputer and so I just wished I just wish that djx1 was smaller and
1:23:49
um you know so so um you know imagine
1:23:55
ladies and gentlemen
1:24:04
our this is nvidia's latest AI
1:24:12
supercomputer and and it's finally called project digits right now and if
1:24:19
you have a good name for it uh reach out to us um uh this here's the amazing
1:24:25
thing this is an AI supercomputer it runs the entire Nvidia AI
1:24:30
stack all of nvidia's software runs on this dgx Cloud runs on
1:24:36
this this sits well somewhere and it's wireless or
1:24:41
you know connect it to your computer it's even a workstation if you like it to be and you could access it you could
1:24:47
you could reach it like a like a cloud supercomputer and nvidia's AI works on
1:24:53
it and um it's based on a a super secret chip that we've been working on called
1:24:58
GB 110 the smallest Grace Blackwell that we make and I have well you know what
1:25:05
let's show let's show everybody insight
1:25:34
isn't it just isn't just it's just so cute and this is the chip that's
1:25:40
inside it is in it is in production this top secret chip uh we
1:25:46
did in collaboration the CPU the gray CPU was a uh is built for NVIDIA in
1:25:52
collaboration with mediatech uh they're the world's leading s so company and they worked with us to build
1:25:58
this CPU this CPU s so and connect it with chipto chip mvy link to the
1:26:04
Blackwell GPU and uh this little this little thing here is in full production
1:26:11
uh we're expecting this computer to uh be available uh around May time frame
1:26:17
and so it's coming at you uh it's just incredible what we could do and it's just I think it's you
1:26:26
really I was trying to figure out do I need more hands or more pockets all right so so uh imagine this
1:26:33
is what it looks like you know who doesn't want one of those and if you if you use
1:26:41
PC Mac you know anything because because uh you know it's it's a cloud platform
1:26:48
it's a cloud computing platform that sits on your desk you could also use it as a l Linux workstation if you like uh
1:26:54
if you would like to have double digits this is what it looks like you
1:26:59
know and you you connect it you connect it together uh uh with connectx and it
1:27:05
has nickel GPU direct all of that out of the
1:27:10
box it's like a supercomputer our entire supercomputing stack uh is available and
1:27:15
so Nvidia Project digits [Applause]
1:27:28
okay well let me let me let me tell you what I told you I told you that we are
1:27:33
in production with three new Blackwells not only is the grace Blackwell
1:27:40
supercomputers mvlink 72s in production all over the world we now have three new
1:27:46
Blackwell systems in production one amazing AI foundational M World
1:27:53
Foundation model the world's first physical AI Foundation model is open available to activate the world's
1:28:00
industries of Robotics and such and three and three robotics three robots
1:28:07
working on uh agentic AI uh human or robots and self-driving
1:28:12
cars uh it's been an incredible year I want to thank all of you for your partnership uh thank all of you for
1:28:18
coming I made you a short video to reflect on last year and look forward to the next year play please w
1:28:36
[Music]
1:29:26
[Applause] [Music]
1:29:51
[Music]
1:29:58
[Music]
1:30:10
[Music]
1:30:15
[Applause] [Music]
1:30:56
[Music]
1:31:14
have a great C us everybody happy New Year thank you

